<dec f='linux-4.14.y/include/linux/mm.h' l='2019' type='void set_dma_reserve(unsigned long new_dma_reserve)'/>
<use f='linux-4.14.y/arch/x86/mm/init.c' l='844' u='c' c='memblock_find_dma_reserve'/>
<def f='linux-4.14.y/mm/page_alloc.c' l='6768' ll='6771' type='void set_dma_reserve(unsigned long new_dma_reserve)'/>
<doc f='linux-4.14.y/mm/page_alloc.c' l='6757'>/**
 * set_dma_reserve - set the specified number of pages reserved in the first zone
 * @new_dma_reserve: The number of pages to mark reserved
 *
 * The per-cpu batchsize and zone watermarks are determined by managed_pages.
 * In the DMA zone, a significant percentage may be consumed by kernel image
 * and other unfreeable allocations which can skew the watermarks badly. This
 * function may optionally be used to account for unfreeable pages in the
 * first zone (e.g., ZONE_DMA). The effect will be lower watermarks and
 * smaller per-cpu batchsize.
 */</doc>
