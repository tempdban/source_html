<dec f='linux-4.14.y/include/linux/mmzone.h' l='435' type='unsigned long'/>
<use f='linux-4.14.y/include/linux/mmzone.h' l='842' u='r' c='managed_zone'/>
<offset>704</offset>
<doc f='linux-4.14.y/include/linux/mmzone.h' l='394'>/*
	 * spanned_pages is the total pages spanned by the zone, including
	 * holes, which is calculated as:
	 * 	spanned_pages = zone_end_pfn - zone_start_pfn;
	 *
	 * present_pages is physical pages existing within the zone, which
	 * is calculated as:
	 *	present_pages = spanned_pages - absent_pages(pages in holes);
	 *
	 * managed_pages is present pages managed by the buddy system, which
	 * is calculated as (reserved_pages includes pages allocated by the
	 * bootmem allocator):
	 *	managed_pages = present_pages - reserved_pages;
	 *
	 * So present_pages may be used by memory hotplug or memory power
	 * management logic to figure out unmanaged pages by checking
	 * (present_pages - managed_pages). And managed_pages should be used
	 * by page allocator and vm scanner to calculate all kinds of watermarks
	 * and thresholds.
	 *
	 * Locking rules:
	 *
	 * zone_start_pfn and spanned_pages are protected by span_seqlock.
	 * It is a seqlock because it has to be read outside of zone-&gt;lock,
	 * and it is done in the main allocator path.  But, it is written
	 * quite infrequently.
	 *
	 * The span_seq lock is declared along with zone-&gt;lock because it is
	 * frequently read in proximity to zone-&gt;lock.  It&apos;s good to
	 * give them a chance of being in the same cacheline.
	 *
	 * Write access to present_pages at runtime should be protected by
	 * mem_hotplug_begin/end(). Any reader who can&apos;t tolerant drift of
	 * present_pages should get_online_mems() to get a stable value.
	 *
	 * Read access to managed_pages should be safe because it&apos;s unsigned
	 * long. Write access to zone-&gt;managed_pages and totalram_pages are
	 * protected by managed_page_count_lock at runtime. Idealy only
	 * adjust_managed_page_count() should be used instead of directly
	 * touching zone-&gt;managed_pages and totalram_pages.
	 */</doc>
<use f='linux-4.14.y/lib/show_mem.c' l='31' u='r' c='show_mem'/>
<use f='linux-4.14.y/mm/nobootmem.c' l='160' u='w' c='reset_node_managed_pages'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='1281' u='w' c='__free_pages_boot_core'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='2111' u='r' c='reserve_highatomic_pageblock'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='4484' u='r' c='nr_free_zone_pages'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='4805' u='r' c='show_free_areas'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='5383' u='r' c='zone_batchsize'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='5493' u='r' c='pageset_set_high_and_batch'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6090' u='w' c='free_area_init_core'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6663' u='w' c='adjust_managed_page_count'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6841' u='r' c='calculate_totalreserve_pages'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6842' u='r' c='calculate_totalreserve_pages'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6866' u='r' c='setup_per_zone_lowmem_reserve'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6882' u='r' c='setup_per_zone_lowmem_reserve'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6901' u='r' c='__setup_per_zone_wmarks'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6908' u='r' c='__setup_per_zone_wmarks'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6922' u='r' c='__setup_per_zone_wmarks'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6939' c='__setup_per_zone_wmarks'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6939' u='r' c='__setup_per_zone_wmarks'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6939' c='__setup_per_zone_wmarks'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6939' u='r' c='__setup_per_zone_wmarks'/>
<use f='linux-4.14.y/mm/vmstat.c' l='159' u='r' c='calculate_normal_threshold'/>
<use f='linux-4.14.y/mm/vmstat.c' l='1520' u='r' c='zoneinfo_show_print'/>
<dec f='linux-4.14.y/include/linux/mmzone.h' l='435' type='unsigned long'/>
<use f='linux-4.14.y/include/linux/mmzone.h' l='842' u='r' c='managed_zone'/>
<offset>704</offset>
<doc f='linux-4.14.y/include/linux/mmzone.h' l='394'>/*
	 * spanned_pages is the total pages spanned by the zone, including
	 * holes, which is calculated as:
	 * 	spanned_pages = zone_end_pfn - zone_start_pfn;
	 *
	 * present_pages is physical pages existing within the zone, which
	 * is calculated as:
	 *	present_pages = spanned_pages - absent_pages(pages in holes);
	 *
	 * managed_pages is present pages managed by the buddy system, which
	 * is calculated as (reserved_pages includes pages allocated by the
	 * bootmem allocator):
	 *	managed_pages = present_pages - reserved_pages;
	 *
	 * So present_pages may be used by memory hotplug or memory power
	 * management logic to figure out unmanaged pages by checking
	 * (present_pages - managed_pages). And managed_pages should be used
	 * by page allocator and vm scanner to calculate all kinds of watermarks
	 * and thresholds.
	 *
	 * Locking rules:
	 *
	 * zone_start_pfn and spanned_pages are protected by span_seqlock.
	 * It is a seqlock because it has to be read outside of zone-&gt;lock,
	 * and it is done in the main allocator path.  But, it is written
	 * quite infrequently.
	 *
	 * The span_seq lock is declared along with zone-&gt;lock because it is
	 * frequently read in proximity to zone-&gt;lock.  It&apos;s good to
	 * give them a chance of being in the same cacheline.
	 *
	 * Write access to present_pages at runtime should be protected by
	 * mem_hotplug_begin/end(). Any reader who can&apos;t tolerant drift of
	 * present_pages should get_online_mems() to get a stable value.
	 *
	 * Read access to managed_pages should be safe because it&apos;s unsigned
	 * long. Write access to zone-&gt;managed_pages and totalram_pages are
	 * protected by managed_page_count_lock at runtime. Idealy only
	 * adjust_managed_page_count() should be used instead of directly
	 * touching zone-&gt;managed_pages and totalram_pages.
	 */</doc>
<use f='linux-4.14.y/lib/show_mem.c' l='31' u='r' c='show_mem'/>
<use f='linux-4.14.y/mm/nobootmem.c' l='160' u='w' c='reset_node_managed_pages'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='1281' u='w' c='__free_pages_boot_core'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='2111' u='r' c='reserve_highatomic_pageblock'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='4484' u='r' c='nr_free_zone_pages'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='4805' u='r' c='show_free_areas'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='5383' u='r' c='zone_batchsize'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='5493' u='r' c='pageset_set_high_and_batch'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6090' u='w' c='free_area_init_core'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6663' u='w' c='adjust_managed_page_count'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6841' u='r' c='calculate_totalreserve_pages'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6842' u='r' c='calculate_totalreserve_pages'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6866' u='r' c='setup_per_zone_lowmem_reserve'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6882' u='r' c='setup_per_zone_lowmem_reserve'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6901' u='r' c='__setup_per_zone_wmarks'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6908' u='r' c='__setup_per_zone_wmarks'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6922' u='r' c='__setup_per_zone_wmarks'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6939' c='__setup_per_zone_wmarks'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6939' u='r' c='__setup_per_zone_wmarks'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6939' c='__setup_per_zone_wmarks'/>
<use f='linux-4.14.y/mm/page_alloc.c' l='6939' u='r' c='__setup_per_zone_wmarks'/>
<use f='linux-4.14.y/mm/vmstat.c' l='159' u='r' c='calculate_normal_threshold'/>
<use f='linux-4.14.y/mm/vmstat.c' l='1520' u='r' c='zoneinfo_show_print'/>
