<def f='linux-4.14.y/drivers/net/ethernet/intel/i40e/i40e_txrx.h' l='272' ll='275' type='unsigned int i40e_txd_use_count(unsigned int size)'/>
<use f='linux-4.14.y/drivers/net/ethernet/intel/i40e/i40e_txrx.h' l='529' u='c' c='i40e_xmit_descriptor_count'/>
<doc f='linux-4.14.y/drivers/net/ethernet/intel/i40e/i40e_txrx.h' l='244'>/**
 * i40e_txd_use_count  - estimate the number of descriptors needed for Tx
 * @size: transmit request size in bytes
 *
 * Due to hardware alignment restrictions (4K alignment), we need to
 * assume that we can have no more than 12K of data per descriptor, even
 * though each descriptor can take up to 16K - 1 bytes of aligned memory.
 * Thus, we need to divide by 12K. But division is slow! Instead,
 * we decompose the operation into shifts and one relatively cheap
 * multiply operation.
 *
 * To divide by 12K, we first divide by 4K, then divide by 3:
 *     To divide by 4K, shift right by 12 bits
 *     To divide by 3, multiply by 85, then divide by 256
 *     (Divide by 256 is done by shifting right by 8 bits)
 * Finally, we add one to round up. Because 256 isn&apos;t an exact multiple of
 * 3, we&apos;ll underestimate near each multiple of 12K. This is actually more
 * accurate as we have 4K - 1 of wiggle room that we can fit into the last
 * segment.  For our purposes this is accurate out to 1M which is orders of
 * magnitude greater than our largest possible GSO size.
 *
 * This would then be implemented as:
 *     return (((size &gt;&gt; 12) * 85) &gt;&gt; 8) + 1;
 *
 * Since multiplication and division are commutative, we can reorder
 * operations into:
 *     return ((size * 85) &gt;&gt; 20) + 1;
 */</doc>
<use f='linux-4.14.y/drivers/net/ethernet/intel/i40e/i40e_txrx.c' l='3366' u='c' c='i40e_xmit_frame_ring'/>
<def f='linux-4.14.y/drivers/net/ethernet/intel/i40evf/i40e_txrx.h' l='255' ll='258' type='unsigned int i40e_txd_use_count(unsigned int size)'/>
<use f='linux-4.14.y/drivers/net/ethernet/intel/i40evf/i40e_txrx.h' l='486' u='c' c='i40e_xmit_descriptor_count'/>
<use f='linux-4.14.y/drivers/net/ethernet/intel/i40evf/i40e_txrx.c' l='2256' u='c' c='i40e_xmit_frame_ring'/>
<doc f='linux-4.14.y/drivers/net/ethernet/intel/i40evf/i40e_txrx.h' l='227'>/**
 * i40e_txd_use_count  - estimate the number of descriptors needed for Tx
 * @size: transmit request size in bytes
 *
 * Due to hardware alignment restrictions (4K alignment), we need to
 * assume that we can have no more than 12K of data per descriptor, even
 * though each descriptor can take up to 16K - 1 bytes of aligned memory.
 * Thus, we need to divide by 12K. But division is slow! Instead,
 * we decompose the operation into shifts and one relatively cheap
 * multiply operation.
 *
 * To divide by 12K, we first divide by 4K, then divide by 3:
 *     To divide by 4K, shift right by 12 bits
 *     To divide by 3, multiply by 85, then divide by 256
 *     (Divide by 256 is done by shifting right by 8 bits)
 * Finally, we add one to round up. Because 256 isn&apos;t an exact multiple of
 * 3, we&apos;ll underestimate near each multiple of 12K. This is actually more
 * accurate as we have 4K - 1 of wiggle room that we can fit into the last
 * segment.  For our purposes this is accurate out to 1M which is orders of
 * magnitude greater than our largest possible GSO size.
 *
 * This would then be implemented as:
 *     return (((size &gt;&gt; 12) * 85) &gt;&gt; 8) + 1;
 *
 * Since multiplication and division are commutative, we can reorder
 * operations into:
 *     return ((size * 85) &gt;&gt; 20) + 1;
 */</doc>
