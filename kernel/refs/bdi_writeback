<def f='linux-4.14.y/include/linux/backing-dev-defs.h' l='85' ll='140'/>
<size>432</size>
<doc f='linux-4.14.y/include/linux/backing-dev-defs.h' l='66'>/*
 * Each wb (bdi_writeback) can perform writeback operations, is measured
 * and throttled, independently.  Without cgroup writeback, each bdi
 * (bdi_writeback) is served by its embedded bdi-&gt;wb.
 *
 * On the default hierarchy, blkcg implicitly enables memcg.  This allows
 * using memcg&apos;s page ownership for attributing writeback IOs, and every
 * memcg - blkcg combination can be served by its own wb by assigning a
 * dedicated wb to each memcg, which enables isolation across different
 * cgroups and propagation of IO back pressure down from the IO layer upto
 * the tasks which are generating the dirty pages to be written back.
 *
 * A cgroup wb is indexed on its bdi by the ID of the associated memcg,
 * refcounted with the number of inodes attached to it, and pins the memcg
 * and the corresponding blkcg.  As the corresponding blkcg for a memcg may
 * change as blkcg is disabled and enabled higher up in the hierarchy, a wb
 * is tested for blkcg after lookup and removed from index on mismatch so
 * that a new wb for the combination can be created.
 */</doc>
<mbr r='bdi_writeback::bdi' o='0' t='struct backing_dev_info *'/>
<mbr r='bdi_writeback::state' o='64' t='unsigned long'/>
<mbr r='bdi_writeback::last_old_flush' o='128' t='unsigned long'/>
<mbr r='bdi_writeback::b_dirty' o='192' t='struct list_head'/>
<mbr r='bdi_writeback::b_io' o='320' t='struct list_head'/>
<mbr r='bdi_writeback::b_more_io' o='448' t='struct list_head'/>
<mbr r='bdi_writeback::b_dirty_time' o='576' t='struct list_head'/>
<mbr r='bdi_writeback::list_lock' o='704' t='spinlock_t'/>
<mbr r='bdi_writeback::stat' o='768' t='struct percpu_counter [4]'/>
<mbr r='bdi_writeback::congested' o='1536' t='struct bdi_writeback_congested *'/>
<mbr r='bdi_writeback::bw_time_stamp' o='1600' t='unsigned long'/>
<mbr r='bdi_writeback::dirtied_stamp' o='1664' t='unsigned long'/>
<mbr r='bdi_writeback::written_stamp' o='1728' t='unsigned long'/>
<mbr r='bdi_writeback::write_bandwidth' o='1792' t='unsigned long'/>
<mbr r='bdi_writeback::avg_write_bandwidth' o='1856' t='unsigned long'/>
<mbr r='bdi_writeback::dirty_ratelimit' o='1920' t='unsigned long'/>
<mbr r='bdi_writeback::balanced_dirty_ratelimit' o='1984' t='unsigned long'/>
<mbr r='bdi_writeback::completions' o='2048' t='struct fprop_local_percpu'/>
<mbr r='bdi_writeback::dirty_exceeded' o='2304' t='int'/>
<mbr r='bdi_writeback::work_lock' o='2336' t='spinlock_t'/>
<mbr r='bdi_writeback::work_list' o='2368' t='struct list_head'/>
<mbr r='bdi_writeback::dwork' o='2496' t='struct delayed_work'/>
<mbr r='bdi_writeback::dirty_sleep' o='3264' t='unsigned long'/>
<mbr r='bdi_writeback::bdi_node' o='3328' t='struct list_head'/>
<def f='linux-4.14.y/include/linux/backing-dev-defs.h' l='85' ll='140'/>
<size>432</size>
<doc f='linux-4.14.y/include/linux/backing-dev-defs.h' l='66'>/*
 * Each wb (bdi_writeback) can perform writeback operations, is measured
 * and throttled, independently.  Without cgroup writeback, each bdi
 * (bdi_writeback) is served by its embedded bdi-&gt;wb.
 *
 * On the default hierarchy, blkcg implicitly enables memcg.  This allows
 * using memcg&apos;s page ownership for attributing writeback IOs, and every
 * memcg - blkcg combination can be served by its own wb by assigning a
 * dedicated wb to each memcg, which enables isolation across different
 * cgroups and propagation of IO back pressure down from the IO layer upto
 * the tasks which are generating the dirty pages to be written back.
 *
 * A cgroup wb is indexed on its bdi by the ID of the associated memcg,
 * refcounted with the number of inodes attached to it, and pins the memcg
 * and the corresponding blkcg.  As the corresponding blkcg for a memcg may
 * change as blkcg is disabled and enabled higher up in the hierarchy, a wb
 * is tested for blkcg after lookup and removed from index on mismatch so
 * that a new wb for the combination can be created.
 */</doc>
<mbr r='bdi_writeback::bdi' o='0' t='struct backing_dev_info *'/>
<mbr r='bdi_writeback::state' o='64' t='unsigned long'/>
<mbr r='bdi_writeback::last_old_flush' o='128' t='unsigned long'/>
<mbr r='bdi_writeback::b_dirty' o='192' t='struct list_head'/>
<mbr r='bdi_writeback::b_io' o='320' t='struct list_head'/>
<mbr r='bdi_writeback::b_more_io' o='448' t='struct list_head'/>
<mbr r='bdi_writeback::b_dirty_time' o='576' t='struct list_head'/>
<mbr r='bdi_writeback::list_lock' o='704' t='spinlock_t'/>
<mbr r='bdi_writeback::stat' o='768' t='struct percpu_counter [4]'/>
<mbr r='bdi_writeback::congested' o='1536' t='struct bdi_writeback_congested *'/>
<mbr r='bdi_writeback::bw_time_stamp' o='1600' t='unsigned long'/>
<mbr r='bdi_writeback::dirtied_stamp' o='1664' t='unsigned long'/>
<mbr r='bdi_writeback::written_stamp' o='1728' t='unsigned long'/>
<mbr r='bdi_writeback::write_bandwidth' o='1792' t='unsigned long'/>
<mbr r='bdi_writeback::avg_write_bandwidth' o='1856' t='unsigned long'/>
<mbr r='bdi_writeback::dirty_ratelimit' o='1920' t='unsigned long'/>
<mbr r='bdi_writeback::balanced_dirty_ratelimit' o='1984' t='unsigned long'/>
<mbr r='bdi_writeback::completions' o='2048' t='struct fprop_local_percpu'/>
<mbr r='bdi_writeback::dirty_exceeded' o='2304' t='int'/>
<mbr r='bdi_writeback::work_lock' o='2336' t='spinlock_t'/>
<mbr r='bdi_writeback::work_list' o='2368' t='struct list_head'/>
<mbr r='bdi_writeback::dwork' o='2496' t='struct delayed_work'/>
<mbr r='bdi_writeback::dirty_sleep' o='3264' t='unsigned long'/>
<mbr r='bdi_writeback::bdi_node' o='3328' t='struct list_head'/>
