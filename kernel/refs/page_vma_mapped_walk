<def f='linux-4.14.y/include/linux/rmap.h' l='205' ll='213'/>
<dec f='linux-4.14.y/include/linux/rmap.h' l='223' type='bool page_vma_mapped_walk(struct page_vma_mapped_walk * pvmw)'/>
<size>56</size>
<mbr r='page_vma_mapped_walk::page' o='0' t='struct page *'/>
<mbr r='page_vma_mapped_walk::vma' o='64' t='struct vm_area_struct *'/>
<mbr r='page_vma_mapped_walk::address' o='128' t='unsigned long'/>
<mbr r='page_vma_mapped_walk::pmd' o='192' t='pmd_t *'/>
<mbr r='page_vma_mapped_walk::pte' o='256' t='pte_t *'/>
<mbr r='page_vma_mapped_walk::ptl' o='320' t='spinlock_t *'/>
<mbr r='page_vma_mapped_walk::flags' o='384' t='unsigned int'/>
<use f='linux-4.14.y/kernel/events/uprobes.c' l='181' u='c' c='__replace_page'/>
<def f='linux-4.14.y/mm/page_vma_mapped.c' l='115' ll='224' type='bool page_vma_mapped_walk(struct page_vma_mapped_walk * pvmw)'/>
<use f='linux-4.14.y/mm/page_vma_mapped.c' l='250' u='c' c='page_mapped_in_vma'/>
<doc f='linux-4.14.y/mm/page_vma_mapped.c' l='91'>/**
 * page_vma_mapped_walk - check if @pvmw-&gt;page is mapped in @pvmw-&gt;vma at
 * @pvmw-&gt;address
 * @pvmw: pointer to struct page_vma_mapped_walk. page, vma, address and flags
 * must be set. pmd, pte and ptl must be NULL.
 *
 * Returns true if the page is mapped in the vma. @pvmw-&gt;pmd and @pvmw-&gt;pte point
 * to relevant page table entries. @pvmw-&gt;ptl is locked. @pvmw-&gt;address is
 * adjusted if needed (for PTE-mapped THPs).
 *
 * If @pvmw-&gt;pmd is set but @pvmw-&gt;pte is not, you have found PMD-mapped page
 * (usually THP). For PTE-mapped THP, you should run page_vma_mapped_walk() in
 * a loop to find all PTEs that map the THP.
 *
 * For HugeTLB pages, @pvmw-&gt;pte is set to the relevant page table entry
 * regardless of which page table level the page is mapped at. @pvmw-&gt;pmd is
 * NULL.
 *
 * Retruns false if there are no more page table entries for the page in
 * the vma. @pvmw-&gt;ptl is unlocked and @pvmw-&gt;pte is unmapped.
 *
 * If you need to stop the walk before page_vma_mapped_walk() returned false,
 * use page_vma_mapped_walk_done(). It will do the housekeeping.
 */</doc>
<use f='linux-4.14.y/mm/rmap.c' l='764' u='c' c='page_referenced_one'/>
<use f='linux-4.14.y/mm/rmap.c' l='902' u='c' c='page_mkclean_one'/>
<use f='linux-4.14.y/mm/rmap.c' l='1368' u='c' c='try_to_unmap_one'/>
<def f='linux-4.14.y/include/linux/rmap.h' l='205' ll='213'/>
<dec f='linux-4.14.y/include/linux/rmap.h' l='223' type='bool page_vma_mapped_walk(struct page_vma_mapped_walk * pvmw)'/>
<size>56</size>
<mbr r='page_vma_mapped_walk::page' o='0' t='struct page *'/>
<mbr r='page_vma_mapped_walk::vma' o='64' t='struct vm_area_struct *'/>
<mbr r='page_vma_mapped_walk::address' o='128' t='unsigned long'/>
<mbr r='page_vma_mapped_walk::pmd' o='192' t='pmd_t *'/>
<mbr r='page_vma_mapped_walk::pte' o='256' t='pte_t *'/>
<mbr r='page_vma_mapped_walk::ptl' o='320' t='spinlock_t *'/>
<mbr r='page_vma_mapped_walk::flags' o='384' t='unsigned int'/>
<use f='linux-4.14.y/kernel/events/uprobes.c' l='181' u='c' c='__replace_page'/>
<def f='linux-4.14.y/mm/page_vma_mapped.c' l='115' ll='224' type='bool page_vma_mapped_walk(struct page_vma_mapped_walk * pvmw)'/>
<use f='linux-4.14.y/mm/page_vma_mapped.c' l='250' u='c' c='page_mapped_in_vma'/>
<doc f='linux-4.14.y/mm/page_vma_mapped.c' l='91'>/**
 * page_vma_mapped_walk - check if @pvmw-&gt;page is mapped in @pvmw-&gt;vma at
 * @pvmw-&gt;address
 * @pvmw: pointer to struct page_vma_mapped_walk. page, vma, address and flags
 * must be set. pmd, pte and ptl must be NULL.
 *
 * Returns true if the page is mapped in the vma. @pvmw-&gt;pmd and @pvmw-&gt;pte point
 * to relevant page table entries. @pvmw-&gt;ptl is locked. @pvmw-&gt;address is
 * adjusted if needed (for PTE-mapped THPs).
 *
 * If @pvmw-&gt;pmd is set but @pvmw-&gt;pte is not, you have found PMD-mapped page
 * (usually THP). For PTE-mapped THP, you should run page_vma_mapped_walk() in
 * a loop to find all PTEs that map the THP.
 *
 * For HugeTLB pages, @pvmw-&gt;pte is set to the relevant page table entry
 * regardless of which page table level the page is mapped at. @pvmw-&gt;pmd is
 * NULL.
 *
 * Retruns false if there are no more page table entries for the page in
 * the vma. @pvmw-&gt;ptl is unlocked and @pvmw-&gt;pte is unmapped.
 *
 * If you need to stop the walk before page_vma_mapped_walk() returned false,
 * use page_vma_mapped_walk_done(). It will do the housekeeping.
 */</doc>
<use f='linux-4.14.y/mm/rmap.c' l='764' u='c' c='page_referenced_one'/>
<use f='linux-4.14.y/mm/rmap.c' l='902' u='c' c='page_mkclean_one'/>
<use f='linux-4.14.y/mm/rmap.c' l='1368' u='c' c='try_to_unmap_one'/>
