<dec f='linux-4.14.y/include/linux/swap.h' l='417' type='struct page * swapin_readahead(swp_entry_t , gfp_t , struct vm_area_struct * vma, unsigned long addr)'/>
<use f='linux-4.14.y/mm/memory.c' l='2893' u='c' c='do_swap_page'/>
<use f='linux-4.14.y/mm/shmem.c' l='1427' u='c' c='shmem_swapin'/>
<def f='linux-4.14.y/mm/swap_state.c' l='554' ll='599' type='struct page * swapin_readahead(swp_entry_t entry, gfp_t gfp_mask, struct vm_area_struct * vma, unsigned long addr)'/>
<doc f='linux-4.14.y/mm/swap_state.c' l='535'>/**
 * swapin_readahead - swap in pages in hope we need them soon
 * @entry: swap entry of this memory
 * @gfp_mask: memory allocation flags
 * @vma: user vma this address belongs to
 * @addr: target address for mempolicy
 *
 * Returns the struct page for entry and addr, after queueing swapin.
 *
 * Primitive swap readahead code. We simply read an aligned block of
 * (1 &lt;&lt; page_cluster) entries in the swap area. This method is chosen
 * because it doesn&apos;t cost us any seek time.  We also make sure to queue
 * the &apos;original&apos; request together with the readahead ones...
 *
 * This has been extended to use the NUMA policies from the mm triggering
 * the readahead.
 *
 * Caller must hold down_read on the vma-&gt;vm_mm if vma is not NULL.
 */</doc>
<dec f='linux-4.14.y/include/linux/swap.h' l='417' type='struct page * swapin_readahead(swp_entry_t , gfp_t , struct vm_area_struct * vma, unsigned long addr)'/>
<use f='linux-4.14.y/mm/memory.c' l='2893' u='c' c='do_swap_page'/>
<use f='linux-4.14.y/mm/shmem.c' l='1427' u='c' c='shmem_swapin'/>
<def f='linux-4.14.y/mm/swap_state.c' l='554' ll='599' type='struct page * swapin_readahead(swp_entry_t entry, gfp_t gfp_mask, struct vm_area_struct * vma, unsigned long addr)'/>
<doc f='linux-4.14.y/mm/swap_state.c' l='535'>/**
 * swapin_readahead - swap in pages in hope we need them soon
 * @entry: swap entry of this memory
 * @gfp_mask: memory allocation flags
 * @vma: user vma this address belongs to
 * @addr: target address for mempolicy
 *
 * Returns the struct page for entry and addr, after queueing swapin.
 *
 * Primitive swap readahead code. We simply read an aligned block of
 * (1 &lt;&lt; page_cluster) entries in the swap area. This method is chosen
 * because it doesn&apos;t cost us any seek time.  We also make sure to queue
 * the &apos;original&apos; request together with the readahead ones...
 *
 * This has been extended to use the NUMA policies from the mm triggering
 * the readahead.
 *
 * Caller must hold down_read on the vma-&gt;vm_mm if vma is not NULL.
 */</doc>
