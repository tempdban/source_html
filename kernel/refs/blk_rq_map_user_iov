<dec f='linux-4.18.y/include/linux/blkdev.h' l='1007' type='int blk_rq_map_user_iov(struct request_queue * , struct request * , struct rq_map_data * , const struct iov_iter * , gfp_t )'/>
<def f='linux-4.18.y/block/blk-map.c' l='114' ll='152' type='int blk_rq_map_user_iov(struct request_queue * q, struct request * rq, struct rq_map_data * map_data, const struct iov_iter * iter, gfp_t gfp_mask)'/>
<dec f='linux-4.18.y/block/blk-map.c' l='153' type='int blk_rq_map_user_iov(struct request_queue * , struct request * , struct rq_map_data * , const struct iov_iter * , gfp_t )'/>
<use f='linux-4.18.y/block/blk-map.c' l='153' c='blk_rq_map_user_iov'/>
<use f='linux-4.18.y/block/blk-map.c' l='153' u='a'/>
<use f='linux-4.18.y/block/blk-map.c' l='153' u='a'/>
<use f='linux-4.18.y/block/blk-map.c' l='166' u='c' c='blk_rq_map_user'/>
<doc f='linux-4.18.y/block/blk-map.c' l='93'>/**
 * blk_rq_map_user_iov - map user data to a request, for passthrough requests
 * @q:		request queue where request should be inserted
 * @rq:		request to map data to
 * @map_data:   pointer to the rq_map_data holding pages (if necessary)
 * @iter:	iovec iterator
 * @gfp_mask:	memory allocation flags
 *
 * Description:
 *    Data will be mapped directly for zero copy I/O, if possible. Otherwise
 *    a kernel bounce buffer is used.
 *
 *    A matching blk_rq_unmap_user() must be issued at the end of I/O, while
 *    still in process context.
 *
 *    Note: The mapped bio may need to be bounced through blk_queue_bounce()
 *    before being submitted to the device, as pages mapped may be out of
 *    reach. It&apos;s the callers responsibility to make sure this happens. The
 *    original bio must be passed back in to blk_rq_unmap_user() for proper
 *    unmapping.
 */</doc>
<use f='linux-4.18.y/block/scsi_ioctl.c' l='353' u='c' c='sg_io'/>
<use f='linux-4.18.y/drivers/scsi/sg.c' l='1824' u='c' c='sg_start_req'/>
