<!doctype html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0"><title>mcs_spinlock.h source code [linux-4.14.y/kernel/locking/mcs_spinlock.h] - Woboq Code Browser</title>
<meta name="woboq:interestingDefinitions" content="mcs_spinlock "/>
<link rel="stylesheet" href="../../../../data/qtcreator.css" title="QtCreator"/>
<link rel="alternate stylesheet" href="../../../../data/kdevelop.css" title="KDevelop"/>
<script type="text/javascript" src="../../../../data/jquery/jquery.min.js"></script>
<script type="text/javascript" src="../../../../data/jquery/jquery-ui.min.js"></script>
<script>var file = 'linux-4.14.y/kernel/locking/mcs_spinlock.h'; var root_path = '../../..'; var data_path = '../../../../data';</script>
<script src='../../../../data/codebrowser.js'></script>
</head>
<body><div id='header'><h1 id='breadcrumb'><span>Browse the source code of </span><a href='../..'>linux-4.14.y</a>/<a href='..'>kernel</a>/<a href='./'>locking</a>/<a href='mcs_spinlock.h.html'>mcs_spinlock.h</a></h1></div>
<hr/><div id='content'><table class="code">
<tr><th id="1">1</th><td><i>/* SPDX-License-Identifier: GPL-2.0 */</i></td></tr>
<tr><th id="2">2</th><td><i>/*</i></td></tr>
<tr><th id="3">3</th><td><i> * MCS lock defines</i></td></tr>
<tr><th id="4">4</th><td><i> *</i></td></tr>
<tr><th id="5">5</th><td><i> * This file contains the main data structure and API definitions of MCS lock.</i></td></tr>
<tr><th id="6">6</th><td><i> *</i></td></tr>
<tr><th id="7">7</th><td><i> * The MCS lock (proposed by Mellor-Crummey and Scott) is a simple spin-lock</i></td></tr>
<tr><th id="8">8</th><td><i> * with the desirable properties of being fair, and with each cpu trying</i></td></tr>
<tr><th id="9">9</th><td><i> * to acquire the lock spinning on a local variable.</i></td></tr>
<tr><th id="10">10</th><td><i> * It avoids expensive cache bouncings that common test-and-set spin-lock</i></td></tr>
<tr><th id="11">11</th><td><i> * implementations incur.</i></td></tr>
<tr><th id="12">12</th><td><i> */</i></td></tr>
<tr><th id="13">13</th><td><u>#<span data-ppcond="13">ifndef</span> <span class="macro" data-ref="_M/__LINUX_MCS_SPINLOCK_H">__LINUX_MCS_SPINLOCK_H</span></u></td></tr>
<tr><th id="14">14</th><td><u>#define <dfn class="macro" id="_M/__LINUX_MCS_SPINLOCK_H" data-ref="_M/__LINUX_MCS_SPINLOCK_H">__LINUX_MCS_SPINLOCK_H</dfn></u></td></tr>
<tr><th id="15">15</th><td></td></tr>
<tr><th id="16">16</th><td><u>#include <a href="../../arch/x86/include/generated/asm/mcs_spinlock.h.html">&lt;asm/mcs_spinlock.h&gt;</a></u></td></tr>
<tr><th id="17">17</th><td></td></tr>
<tr><th id="18">18</th><td><b>struct</b> <dfn class="type def" id="mcs_spinlock" title='mcs_spinlock' data-ref="mcs_spinlock">mcs_spinlock</dfn> {</td></tr>
<tr><th id="19">19</th><td>	<b>struct</b> <a class="type" href="#mcs_spinlock" title='mcs_spinlock' data-ref="mcs_spinlock">mcs_spinlock</a> *<dfn class="decl field" id="mcs_spinlock::next" title='mcs_spinlock::next' data-ref="mcs_spinlock::next">next</dfn>;</td></tr>
<tr><th id="20">20</th><td>	<em>int</em> <dfn class="decl field" id="mcs_spinlock::locked" title='mcs_spinlock::locked' data-ref="mcs_spinlock::locked">locked</dfn>; <i>/* 1 if lock acquired */</i></td></tr>
<tr><th id="21">21</th><td>	<em>int</em> <dfn class="decl field" id="mcs_spinlock::count" title='mcs_spinlock::count' data-ref="mcs_spinlock::count">count</dfn>;  <i>/* nesting count, see qspinlock.c */</i></td></tr>
<tr><th id="22">22</th><td>};</td></tr>
<tr><th id="23">23</th><td></td></tr>
<tr><th id="24">24</th><td><u>#<span data-ppcond="24">ifndef</span> <span class="macro" data-ref="_M/arch_mcs_spin_lock_contended">arch_mcs_spin_lock_contended</span></u></td></tr>
<tr><th id="25">25</th><td><i>/*</i></td></tr>
<tr><th id="26">26</th><td><i> * Using smp_load_acquire() provides a memory barrier that ensures</i></td></tr>
<tr><th id="27">27</th><td><i> * subsequent operations happen after the lock is acquired.</i></td></tr>
<tr><th id="28">28</th><td><i> */</i></td></tr>
<tr><th id="29">29</th><td><u>#define <dfn class="macro" id="_M/arch_mcs_spin_lock_contended" data-ref="_M/arch_mcs_spin_lock_contended">arch_mcs_spin_lock_contended</dfn>(l)					\</u></td></tr>
<tr><th id="30">30</th><td><u>do {									\</u></td></tr>
<tr><th id="31">31</th><td><u>	while (!(smp_load_acquire(l)))					\</u></td></tr>
<tr><th id="32">32</th><td><u>		<a class="ref fn" href="../../arch/x86/include/asm/processor.h.html#cpu_relax" title='cpu_relax' data-ref="cpu_relax">cpu_relax</a>();						\</u></td></tr>
<tr><th id="33">33</th><td><u>} while (0)</u></td></tr>
<tr><th id="34">34</th><td><u>#<span data-ppcond="24">endif</span></u></td></tr>
<tr><th id="35">35</th><td></td></tr>
<tr><th id="36">36</th><td><u>#<span data-ppcond="36">ifndef</span> <span class="macro" data-ref="_M/arch_mcs_spin_unlock_contended">arch_mcs_spin_unlock_contended</span></u></td></tr>
<tr><th id="37">37</th><td><i>/*</i></td></tr>
<tr><th id="38">38</th><td><i> * smp_store_release() provides a memory barrier to ensure all</i></td></tr>
<tr><th id="39">39</th><td><i> * operations in the critical section has been completed before</i></td></tr>
<tr><th id="40">40</th><td><i> * unlocking.</i></td></tr>
<tr><th id="41">41</th><td><i> */</i></td></tr>
<tr><th id="42">42</th><td><u>#define <dfn class="macro" id="_M/arch_mcs_spin_unlock_contended" data-ref="_M/arch_mcs_spin_unlock_contended">arch_mcs_spin_unlock_contended</dfn>(l)				\</u></td></tr>
<tr><th id="43">43</th><td><u>	smp_store_release((l), 1)</u></td></tr>
<tr><th id="44">44</th><td><u>#<span data-ppcond="36">endif</span></u></td></tr>
<tr><th id="45">45</th><td></td></tr>
<tr><th id="46">46</th><td><i>/*</i></td></tr>
<tr><th id="47">47</th><td><i> * Note: the smp_load_acquire/smp_store_release pair is not</i></td></tr>
<tr><th id="48">48</th><td><i> * sufficient to form a full memory barrier across</i></td></tr>
<tr><th id="49">49</th><td><i> * cpus for many architectures (except x86) for mcs_unlock and mcs_lock.</i></td></tr>
<tr><th id="50">50</th><td><i> * For applications that need a full barrier across multiple cpus</i></td></tr>
<tr><th id="51">51</th><td><i> * with mcs_unlock and mcs_lock pair, smp_mb__after_unlock_lock() should be</i></td></tr>
<tr><th id="52">52</th><td><i> * used after mcs_lock.</i></td></tr>
<tr><th id="53">53</th><td><i> */</i></td></tr>
<tr><th id="54">54</th><td></td></tr>
<tr><th id="55">55</th><td><i>/*</i></td></tr>
<tr><th id="56">56</th><td><i> * In order to acquire the lock, the caller should declare a local node and</i></td></tr>
<tr><th id="57">57</th><td><i> * pass a reference of the node to this function in addition to the lock.</i></td></tr>
<tr><th id="58">58</th><td><i> * If the lock has already been acquired, then this will proceed to spin</i></td></tr>
<tr><th id="59">59</th><td><i> * on this node-&gt;locked until the previous lock holder sets the node-&gt;locked</i></td></tr>
<tr><th id="60">60</th><td><i> * in mcs_spin_unlock().</i></td></tr>
<tr><th id="61">61</th><td><i> */</i></td></tr>
<tr><th id="62">62</th><td><em>static</em> <a class="macro" href="../../include/linux/compiler-gcc.h.html#95" title="inline __attribute__((always_inline, unused)) __attribute__((no_instrument_function))" data-ref="_M/inline"><b>inline</b></a></td></tr>
<tr><th id="63">63</th><td><em>void</em> <dfn class="decl def fn" id="mcs_spin_lock" title='mcs_spin_lock' data-ref="mcs_spin_lock">mcs_spin_lock</dfn>(<b>struct</b> <a class="type" href="#mcs_spinlock" title='mcs_spinlock' data-ref="mcs_spinlock">mcs_spinlock</a> **<dfn class="local col1 decl" id="1lock" title='lock' data-type='struct mcs_spinlock **' data-ref="1lock">lock</dfn>, <b>struct</b> <a class="type" href="#mcs_spinlock" title='mcs_spinlock' data-ref="mcs_spinlock">mcs_spinlock</a> *<dfn class="local col2 decl" id="2node" title='node' data-type='struct mcs_spinlock *' data-ref="2node">node</dfn>)</td></tr>
<tr><th id="64">64</th><td>{</td></tr>
<tr><th id="65">65</th><td>	<b>struct</b> <a class="type" href="#mcs_spinlock" title='mcs_spinlock' data-ref="mcs_spinlock">mcs_spinlock</a> *<dfn class="local col3 decl" id="3prev" title='prev' data-type='struct mcs_spinlock *' data-ref="3prev">prev</dfn>;</td></tr>
<tr><th id="66">66</th><td></td></tr>
<tr><th id="67">67</th><td>	<i>/* Init node */</i></td></tr>
<tr><th id="68">68</th><td>	<a class="local col2 ref" href="#2node" title='node' data-ref="2node">node</a>-&gt;<a class="ref field" href="#mcs_spinlock::locked" title='mcs_spinlock::locked' data-ref="mcs_spinlock::locked">locked</a> = <var>0</var>;</td></tr>
<tr><th id="69">69</th><td>	<a class="local col2 ref" href="#2node" title='node' data-ref="2node">node</a>-&gt;<a class="ref field" href="#mcs_spinlock::next" title='mcs_spinlock::next' data-ref="mcs_spinlock::next">next</a>   = <a class="macro" href="../../include/linux/stddef.h.html#8" title="((void *)0)" data-ref="_M/NULL">NULL</a>;</td></tr>
<tr><th id="70">70</th><td></td></tr>
<tr><th id="71">71</th><td>	<i>/*</i></td></tr>
<tr><th id="72">72</th><td><i>	 * We rely on the full barrier with global transitivity implied by the</i></td></tr>
<tr><th id="73">73</th><td><i>	 * below xchg() to order the initialization stores above against any</i></td></tr>
<tr><th id="74">74</th><td><i>	 * observation of @node. And to provide the ACQUIRE ordering associated</i></td></tr>
<tr><th id="75">75</th><td><i>	 * with a LOCK primitive.</i></td></tr>
<tr><th id="76">76</th><td><i>	 */</i></td></tr>
<tr><th id="77">77</th><td>	<a class="local col3 ref" href="#3prev" title='prev' data-ref="3prev">prev</a> = <a class="macro" href="../../arch/x86/include/asm/cmpxchg.h.html#78" title="({ __typeof__ (*((lock))) __ret = ((node)); switch (sizeof(*((lock)))) { case 1: asm volatile (&quot;&quot; &quot;xchg&quot; &quot;b %b0, %1\n&quot; : &quot;+q&quot; (__ret), &quot;+m&quot; (*((lock))) : : &quot;memory&quot;, &quot;cc&quot;); break; case 2: asm volatile (&quot;&quot; &quot;xchg&quot; &quot;w %w0, %1\n&quot; : &quot;+r&quot; (__ret), &quot;+m&quot; (*((lock))) : : &quot;memory&quot;, &quot;cc&quot;); break; case 4: asm volatile (&quot;&quot; &quot;xchg&quot; &quot;l %0, %1\n&quot; : &quot;+r&quot; (__ret), &quot;+m&quot; (*((lock))) : : &quot;memory&quot;, &quot;cc&quot;); break; case 8: asm volatile (&quot;&quot; &quot;xchg&quot; &quot;q %q0, %1\n&quot; : &quot;+r&quot; (__ret), &quot;+m&quot; (*((lock))) : : &quot;memory&quot;, &quot;cc&quot;); break; default: __xchg_wrong_size(); } __ret; })" data-ref="_M/xchg">xchg</a>(<a class="local col1 ref" href="#1lock" title='lock' data-ref="1lock">lock</a>, <a class="local col2 ref" href="#2node" title='node' data-ref="2node">node</a>);</td></tr>
<tr><th id="78">78</th><td>	<b>if</b> (<a class="macro" href="../../include/linux/compiler.h.html#76" title="__builtin_expect(!!(prev == ((void *)0)), 1)" data-ref="_M/likely">likely</a>(<a class="local col3 ref" href="#3prev" title='prev' data-ref="3prev">prev</a> == <a class="macro" href="../../include/linux/stddef.h.html#8" title="((void *)0)" data-ref="_M/NULL">NULL</a>)) {</td></tr>
<tr><th id="79">79</th><td>		<i>/*</i></td></tr>
<tr><th id="80">80</th><td><i>		 * Lock acquired, don't need to set node-&gt;locked to 1. Threads</i></td></tr>
<tr><th id="81">81</th><td><i>		 * only spin on its own node-&gt;locked value for lock acquisition.</i></td></tr>
<tr><th id="82">82</th><td><i>		 * However, since this thread can immediately acquire the lock</i></td></tr>
<tr><th id="83">83</th><td><i>		 * and does not proceed to spin on its own node-&gt;locked, this</i></td></tr>
<tr><th id="84">84</th><td><i>		 * value won't be used. If a debug mode is needed to</i></td></tr>
<tr><th id="85">85</th><td><i>		 * audit lock status, then set node-&gt;locked value here.</i></td></tr>
<tr><th id="86">86</th><td><i>		 */</i></td></tr>
<tr><th id="87">87</th><td>		<b>return</b>;</td></tr>
<tr><th id="88">88</th><td>	}</td></tr>
<tr><th id="89">89</th><td>	<a class="macro" href="../../include/linux/compiler.h.html#262" title="({ union { typeof(prev-&gt;next) __val; char __c[1]; } __u = { .__val = ( typeof(prev-&gt;next)) (node) }; __write_once_size(&amp;(prev-&gt;next), __u.__c, sizeof(prev-&gt;next)); __u.__val; })" data-ref="_M/WRITE_ONCE">WRITE_ONCE</a>(<a class="local col3 ref" href="#3prev" title='prev' data-ref="3prev">prev</a>-&gt;<a class="ref field" href="#mcs_spinlock::next" title='mcs_spinlock::next' data-ref="mcs_spinlock::next">next</a>, <a class="local col2 ref" href="#2node" title='node' data-ref="2node">node</a>);</td></tr>
<tr><th id="90">90</th><td></td></tr>
<tr><th id="91">91</th><td>	<i>/* Wait until the lock holder passes the lock down. */</i></td></tr>
<tr><th id="92">92</th><td>	<a class="macro" href="#29" title="do { while (!(({ typeof(*&amp;node-&gt;locked) ___p1 = ({ union { typeof(*&amp;node-&gt;locked) __val; char __c[1]; } __u; if (1) __read_once_size(&amp;(*&amp;node-&gt;locked), __u.__c, sizeof(*&amp;node-&gt;locked)); else __read_once_size_nocheck(&amp;(*&amp;node-&gt;locked), __u.__c, sizeof(*&amp;node-&gt;locked)); do { } while (0); __u.__val; }); do { bool __cond = !((sizeof(*&amp;node-&gt;locked) == sizeof(char) || sizeof(*&amp;node-&gt;locked) == sizeof(short) || sizeof(*&amp;node-&gt;locked) == sizeof(int) || sizeof(*&amp;node-&gt;locked) == sizeof(long))); extern void __compiletime_assert_92(void) ; if (__cond) __compiletime_assert_92(); do { ((void)sizeof(char[1 - 2 * __cond])); } while (0); } while (0); __asm__ __volatile__(&quot;&quot;: : :&quot;memory&quot;); ___p1; }))) cpu_relax(); } while (0)" data-ref="_M/arch_mcs_spin_lock_contended">arch_mcs_spin_lock_contended</a>(&amp;<a class="local col2 ref" href="#2node" title='node' data-ref="2node">node</a>-&gt;<a class="ref field" href="#mcs_spinlock::locked" title='mcs_spinlock::locked' data-ref="mcs_spinlock::locked">locked</a>);</td></tr>
<tr><th id="93">93</th><td>}</td></tr>
<tr><th id="94">94</th><td></td></tr>
<tr><th id="95">95</th><td><i>/*</i></td></tr>
<tr><th id="96">96</th><td><i> * Releases the lock. The caller should pass in the corresponding node that</i></td></tr>
<tr><th id="97">97</th><td><i> * was used to acquire the lock.</i></td></tr>
<tr><th id="98">98</th><td><i> */</i></td></tr>
<tr><th id="99">99</th><td><em>static</em> <a class="macro" href="../../include/linux/compiler-gcc.h.html#95" title="inline __attribute__((always_inline, unused)) __attribute__((no_instrument_function))" data-ref="_M/inline"><b>inline</b></a></td></tr>
<tr><th id="100">100</th><td><em>void</em> <dfn class="decl def fn" id="mcs_spin_unlock" title='mcs_spin_unlock' data-ref="mcs_spin_unlock">mcs_spin_unlock</dfn>(<b>struct</b> <a class="type" href="#mcs_spinlock" title='mcs_spinlock' data-ref="mcs_spinlock">mcs_spinlock</a> **<dfn class="local col4 decl" id="4lock" title='lock' data-type='struct mcs_spinlock **' data-ref="4lock">lock</dfn>, <b>struct</b> <a class="type" href="#mcs_spinlock" title='mcs_spinlock' data-ref="mcs_spinlock">mcs_spinlock</a> *<dfn class="local col5 decl" id="5node" title='node' data-type='struct mcs_spinlock *' data-ref="5node">node</dfn>)</td></tr>
<tr><th id="101">101</th><td>{</td></tr>
<tr><th id="102">102</th><td>	<b>struct</b> <a class="type" href="#mcs_spinlock" title='mcs_spinlock' data-ref="mcs_spinlock">mcs_spinlock</a> *<dfn class="local col6 decl" id="6next" title='next' data-type='struct mcs_spinlock *' data-ref="6next">next</dfn> = <a class="macro" href="../../include/linux/compiler.h.html#254" title="({ union { typeof(node-&gt;next) __val; char __c[1]; } __u; if (1) __read_once_size(&amp;(node-&gt;next), __u.__c, sizeof(node-&gt;next)); else __read_once_size_nocheck(&amp;(node-&gt;next), __u.__c, sizeof(node-&gt;next)); do { } while (0); __u.__val; })" data-ref="_M/READ_ONCE">READ_ONCE</a>(<a class="local col5 ref" href="#5node" title='node' data-ref="5node">node</a>-&gt;<a class="ref field" href="#mcs_spinlock::next" title='mcs_spinlock::next' data-ref="mcs_spinlock::next">next</a>);</td></tr>
<tr><th id="103">103</th><td></td></tr>
<tr><th id="104">104</th><td>	<b>if</b> (<a class="macro" href="../../include/linux/compiler.h.html#76" title="__builtin_expect(!!(!next), 1)" data-ref="_M/likely">likely</a>(!<a class="local col6 ref" href="#6next" title='next' data-ref="6next">next</a>)) {</td></tr>
<tr><th id="105">105</th><td>		<i>/*</i></td></tr>
<tr><th id="106">106</th><td><i>		 * Release the lock by setting it to NULL</i></td></tr>
<tr><th id="107">107</th><td><i>		 */</i></td></tr>
<tr><th id="108">108</th><td>		<b>if</b> (<a class="macro" href="../../include/linux/compiler.h.html#76" title="__builtin_expect(!!(({ __typeof__(*((lock))) __ret; __typeof__(*((lock))) __old = ((node)); __typeof__(*((lock))) __new = ((((void *)0))); switch ((sizeof(*(lock)))) { case 1: { volatile u8 *__ptr = (volatile u8 *)((lock)); asm volatile(&quot;.pushsection .smp_locks,\&quot;a\&quot;\n&quot; &quot;.balign 4\n&quot; &quot;.long 671f - .\n&quot; &quot;.popsection\n&quot; &quot;671:&quot; &quot;\n\tlock; &quot; &quot;cmpxchgb %2,%1&quot; : &quot;=a&quot; (__ret), &quot;+m&quot; (*__ptr) : &quot;q&quot; (__new), &quot;0&quot; (__old) : &quot;memory&quot;); break; } case 2: { volatile u16 *__ptr = (volatile u16 *)((lock)); asm volatile(&quot;.pushsection .smp_locks,\&quot;a\&quot;\n&quot; &quot;.balign 4\n&quot; &quot;.long 671f - .\n&quot; &quot;.popsection\n&quot; &quot;671:&quot; &quot;\n\tlock; &quot; &quot;cmpxchgw %2,%1&quot; : &quot;=a&quot; (__ret), &quot;+m&quot; (*__ptr) : &quot;r&quot; (__new), &quot;0&quot; (__old) : &quot;memory&quot;); break; } case 4: { volatile u32 *__ptr = (volatile u32 *)((lock)); asm volatile(&quot;.pushsection .smp_locks,\&quot;a\&quot;\n&quot; &quot;.balign 4\n&quot; &quot;.long 671f - .\n&quot; &quot;.popsection\n&quot; &quot;671:&quot; &quot;\n\tlock; &quot; &quot;cmpxchgl %2,%1&quot; : &quot;=a&quot; (__ret), &quot;+m&quot; (*__ptr) : &quot;r&quot; (__new), &quot;0&quot; (__old) : &quot;memory&quot;); break; } case 8: { volatile u64 *__ptr = (volatile u64 *)((lock)); asm volatile(&quot;.pushsection .smp_locks,\&quot;a\&quot;\n&quot; &quot;.balign 4\n&quot; &quot;.long 671f - .\n&quot; &quot;.popsection\n&quot; &quot;671:&quot; &quot;\n\tlock; &quot; &quot;cmpxchgq %2,%1&quot; : &quot;=a&quot; (__ret), &quot;+m&quot; (*__ptr) : &quot;r&quot; (__new), &quot;0&quot; (__old) : &quot;memory&quot;); break; } default: __cmpxchg_wrong_size(); } __ret; }) == node), 1)" data-ref="_M/likely">likely</a>(<a class="macro" href="../../include/linux/atomic.h.html#457" title="cmpxchg" data-ref="_M/cmpxchg_release">cmpxchg_release</a>(<a class="local col4 ref" href="#4lock" title='lock' data-ref="4lock">lock</a>, <a class="local col5 ref" href="#5node" title='node' data-ref="5node">node</a>, <a class="macro" href="../../include/linux/stddef.h.html#8" title="((void *)0)" data-ref="_M/NULL">NULL</a>) == <a class="local col5 ref" href="#5node" title='node' data-ref="5node">node</a>))</td></tr>
<tr><th id="109">109</th><td>			<b>return</b>;</td></tr>
<tr><th id="110">110</th><td>		<i>/* Wait until the next pointer is set */</i></td></tr>
<tr><th id="111">111</th><td>		<b>while</b> (!(<a class="local col6 ref" href="#6next" title='next' data-ref="6next">next</a> = <a class="macro" href="../../include/linux/compiler.h.html#254" title="({ union { typeof(node-&gt;next) __val; char __c[1]; } __u; if (1) __read_once_size(&amp;(node-&gt;next), __u.__c, sizeof(node-&gt;next)); else __read_once_size_nocheck(&amp;(node-&gt;next), __u.__c, sizeof(node-&gt;next)); do { } while (0); __u.__val; })" data-ref="_M/READ_ONCE">READ_ONCE</a>(<a class="local col5 ref" href="#5node" title='node' data-ref="5node">node</a>-&gt;<a class="ref field" href="#mcs_spinlock::next" title='mcs_spinlock::next' data-ref="mcs_spinlock::next">next</a>)))</td></tr>
<tr><th id="112">112</th><td>			<a class="ref fn" href="../../arch/x86/include/asm/processor.h.html#cpu_relax" title='cpu_relax' data-ref="cpu_relax">cpu_relax</a>();</td></tr>
<tr><th id="113">113</th><td>	}</td></tr>
<tr><th id="114">114</th><td></td></tr>
<tr><th id="115">115</th><td>	<i>/* Pass lock to next waiter. */</i></td></tr>
<tr><th id="116">116</th><td>	<a class="macro" href="#42" title="do { do { bool __cond = !((sizeof(*(&amp;next-&gt;locked)) == sizeof(char) || sizeof(*(&amp;next-&gt;locked)) == sizeof(short) || sizeof(*(&amp;next-&gt;locked)) == sizeof(int) || sizeof(*(&amp;next-&gt;locked)) == sizeof(long))); extern void __compiletime_assert_116(void) ; if (__cond) __compiletime_assert_116(); do { ((void)sizeof(char[1 - 2 * __cond])); } while (0); } while (0); __asm__ __volatile__(&quot;&quot;: : :&quot;memory&quot;); ({ union { typeof(*(&amp;next-&gt;locked)) __val; char __c[1]; } __u = { .__val = ( typeof(*(&amp;next-&gt;locked))) (1) }; __write_once_size(&amp;(*(&amp;next-&gt;locked)), __u.__c, sizeof(*(&amp;next-&gt;locked))); __u.__val; }); } while (0)" data-ref="_M/arch_mcs_spin_unlock_contended">arch_mcs_spin_unlock_contended</a>(&amp;<a class="local col6 ref" href="#6next" title='next' data-ref="6next">next</a>-&gt;<a class="ref field" href="#mcs_spinlock::locked" title='mcs_spinlock::locked' data-ref="mcs_spinlock::locked">locked</a>);</td></tr>
<tr><th id="117">117</th><td>}</td></tr>
<tr><th id="118">118</th><td></td></tr>
<tr><th id="119">119</th><td><u>#<span data-ppcond="13">endif</span> /* __LINUX_MCS_SPINLOCK_H */</u></td></tr>
<tr><th id="120">120</th><td></td></tr>
</table><hr/><p id='footer'>
Generated while processing <a href='qspinlock.c.html'>linux-4.14.y/kernel/locking/qspinlock.c</a><br/>Generated on <em>2018-Jul-30</em> from project linux-4.14.y revision <em>linux-4.14.y</em><br />Powered by <a href='https://woboq.com'><img alt='Woboq' src='https://code.woboq.org/woboq-16.png' width='41' height='16' /></a> <a href='https://code.woboq.org'>Code Browser</a> 2.1
<br/>Generator usage only permitted with license.</p>
</div></body></html>
